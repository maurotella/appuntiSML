\section{L'algoritmo \textit{Nearest Neighbor} (NN)}

Verrà introdotto ora l'algoritmo di \textbf{\textit{Nearest Neighbor} (NN)} per la
classificazione binaria con \textit{feature} numeriche:
$$ \X = \RN^d \qquad\qquad \Y = \{-1,1\} $$

NN non è un'istanza di ERM in quanto non punta a minimizzare $\loss_S$.

\textbf{
L'idea di NN è la sueguente:
\begin{itemize}
    \item Predici ogni punto del \textit{training set} con la propria etichetta;
    \item Predici gli altri punti con l'etichetta del punto del \textit{training set}
        che è più vicino al punto interessato.
\end{itemize}
}

Più formalmente, dato un \textit{training set}:
$$ S = \{(x_1,y_1),\dots,(x_m,y_m)\} $$
l'algoritmo $\Ann$ genera un classificatore $\hnn:\RN \rightarrow \{-1,1\}$ definito
come segue:
$$ \hnn(x) = \text{etichetta $y_t$ del punto $x_t \in S$ più vicino a x} $$

Se a minimizzare la distanza con $x$ sono più punti, si predirrà l'etichetta più
presente tra i putni vicini. Se non c'è una maggioranza di etichette tra i punti
più vicini si predirrà un valore di default $\in \{-1,1\}$.

Presi due punti $x=(x_1,\dots,x_d)$ e $x_t=(x_{t,1},\dots,x_{t,d})$, la distanza
$||x-x_t||$ verrà calcolata tramite la distanza euclidea:
$$||x-x_t|| = \sqrt{\sum_{i=1}^d (x_i-x_{t,i})^2}$$

Ogni classificatore binario $\pred : \RN^d \rightarrow \{-1,1\}$ partiziona $\RN^d$
in due regioni (come mostrato in figura \ref{fig:voronoi}):
$$ \colorbox{orange}{$\{ x \in \RN^d : \pred(x)=1 \}$} \quad , \quad 
   \colorbox{cyan}{$\{ x \in \RN^d : \pred(x)=-1 \}$} $$

\begin{figure}[h]
    \centering
    \input{figures/voronoi.tex}
    \caption{Diagramma di Voronoi in $\RN^2$\label{fig:voronoi}}
\end{figure}